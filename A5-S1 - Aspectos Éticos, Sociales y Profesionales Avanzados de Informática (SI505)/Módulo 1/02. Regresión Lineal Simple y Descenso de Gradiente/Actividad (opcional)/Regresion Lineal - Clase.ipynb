{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_gQEh1UYYsW"
   },
   "outputs": [],
   "source": [
    "!pip install -q rnutil\n",
    "import rnutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "YvbMMsiGYYsh"
   },
   "source": [
    "# Ejercicio -   Regresión Lineal Univariada\n",
    "\n",
    "En este ejercicio, tu objetivo será implementar el método `forward` de un modelo de Regresión Lineal Univariada (es decir, con una sola variable de entrada). No debés implementar ningún otro método.\n",
    "\n",
    "La función se encuentra en la clase `RegresionLinealUnivariada`.\n",
    "\n",
    "Luego, ejecuta las pruebas para verificar que implementaste correctamente el modelo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wuoLy2QYYsi"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "class RegresionLinealUnivariada:\n",
    "    '''\n",
    "    Esta clase permite entrenar modelos de regresión lineal univariada, cuya función de predicción es:\n",
    "    y = w x + b\n",
    "    Los parámetros w y b son números flotantes\n",
    "    La entrada x debe ser unidimensional.\n",
    "    '''\n",
    "\n",
    "    def __init__(self,w:float,b:float=0):\n",
    "        self.w=w\n",
    "        self.b=b\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(w = {self.w:.5f}, b = {self.b:.5f})\"\n",
    "\n",
    "    def forward(self,x:np.ndarray):\n",
    "        '''\n",
    "        :param x: vector 1D con valores de entrada\n",
    "        :return: la predicción x*w+b\n",
    "        '''\n",
    "        assert (len(x.shape) == 1)\n",
    "\n",
    "        n=len(x)\n",
    "        y=np.zeros(n)\n",
    "            \n",
    "        # TODO calcular la salida y en base a: x, self.w, y self.b\n",
    "        y = self.w*x+self.b\n",
    "        # FIN TODO\n",
    "        assert len(y) == n, \"La cantidad de elementos de y es distinta de la de x\"\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def backward(self,x:np.ndarray,y_true:np.ndarray)->(float,float):\n",
    "        '''\n",
    "        Calcula las derivadas de los parámetros del modelo con respecto \n",
    "        al error cuadrático medio y al conjunto de datos (x,y)\n",
    "        No necesitas implementar nada aqui\n",
    "        :param x: vector 1D con los valores de entrada\n",
    "        :param y: vector 1D con los valores de salida _verdaderos_ \n",
    "        :return derivada del error respecto de w y b\n",
    "        '''\n",
    "        \n",
    "        y = self.forward(x)\n",
    "        # calculo de derivadas\n",
    "        dEdw = 2 * ((y - y_true) * x).mean()\n",
    "        dEdb = 2 * (y - y_true).mean()\n",
    "        return dEdw,dEdb\n",
    "\n",
    "    def fit(self,x:np.ndarray,y:np.ndarray,lr:float=0.001,epochs:int=100):\n",
    "        '''\n",
    "        No necesitas implementar nada aqui\n",
    "        Entrena el modelo (ajusta los parámetros) para minimizar el error cuadrático medio\n",
    "        Utilizando descenso de gradiente \n",
    "        :param x: vector 1D con los valores de entrada\n",
    "        :param y: vector 1D con los valores de salida _verdaderos_ \n",
    "        :param lr: velocidad de aprendizaje (learning rate)\n",
    "        :param epochs: cantidad de iteraciones de aprendizaje\n",
    "        '''\n",
    "        \n",
    "        assert (len(x.shape) == 1)\n",
    "        assert (len(y.shape) == 1)\n",
    "        assert ( len(y) == len(x))\n",
    "        n = len(x)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            dEdw,dEdb=self.backward(x,y)\n",
    "            # actualizo los parámetros\n",
    "            self.w = self.w - lr * dEdw\n",
    "            self.b = self.b - lr * dEdb\n",
    "            print(f\"Epoch {i+1}/{epochs} => Error = {self.error(x,y)}\")\n",
    "        \n",
    "    def error(self,x:np.ndarray,y_true:np.ndarray)->float:\n",
    "        '''\n",
    "        Error cuadrático medio (MSE) del modelo\n",
    "        :param x: vector 1D con los valores de entrada\n",
    "        :param y: vector 1D con los valores de salida _verdaderos_ \n",
    "        :return flotante con el error promedio del modelo entre todos los ejemplos\n",
    "        '''\n",
    "        \n",
    "        y = self.forward(x)\n",
    "        d2 = (y_true-y)**2\n",
    "        return d2.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Oj-lPgmYYst"
   },
   "source": [
    "# Ejecuta el siguiente bloque para verificar que la función `forward` está bien implementada\n",
    "\n",
    "Cuando todos los vectores son iguales a los esperados, quiere decir que está bien implementado el forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EyHujpuYYsu"
   },
   "outputs": [],
   "source": [
    "\n",
    "x=np.array([1.0,2.0,3.0])\n",
    "\n",
    "rl1=RegresionLinealUnivariada(w=0,b=0.0)\n",
    "y=rl1.forward(x)\n",
    "rnutil.verificar_igualdad(y,np.zeros(3))\n",
    "\n",
    "rl2=RegresionLinealUnivariada(w=1.0,b=0.0)\n",
    "y=rl2.forward(x)\n",
    "rnutil.verificar_igualdad(y,x)\n",
    "\n",
    "rl3=RegresionLinealUnivariada(w=0.0,b=1.0)\n",
    "y=rl3.forward(x)\n",
    "rnutil.verificar_igualdad(y,np.ones(3))\n",
    "\n",
    "rl4=RegresionLinealUnivariada(w=1.0,b=1.0)\n",
    "y=rl4.forward(x)\n",
    "rnutil.verificar_igualdad(y,np.ones(3)+x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEbEZ6a0YYs8"
   },
   "source": [
    "# Verifica que el modelo se entrena correctamente.\n",
    "Utilizando la función `fit` vamos a entrenar el modelo con los datos `x` e `y`. \n",
    "\n",
    "* Primero, se crea el modelo inicializando con valores aleatorios de `w` y `b`. \n",
    "* Luego se visualiza el modelo inicial con los parámetros aleatorios.\n",
    "* Después se entrena el modelo con descenso de gradiente con `fit`\n",
    "* Finalmente, se visualiza el modelo final con los parámetros optimizados.\n",
    "\n",
    "**Nota:** El entrenamiento _no_ va a disminuir el error si no está implementada la función forward más arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKOGp7eeYYs_"
   },
   "outputs": [],
   "source": [
    "# Carga del dataset\n",
    "\n",
    "data=rnutil.load_dataset_numpy(\"study_regression_small.csv\")\n",
    "x,y=data[:,0],data[:,1]\n",
    "\n",
    "print(\"Inicialización aleatoria del modelo; vuelve a correr esta celda para obtener otros resultados\")\n",
    "w_random=np.random.rand()\n",
    "b_random=np.random.rand()\n",
    "rl=RegresionLinealUnivariada(w_random,b_random)\n",
    "\n",
    "# visualiza el modelo inicial aleatorio y los datos\n",
    "rnutil.plot_regresion_lineal_univariada(rl.w,rl.b,x,y,title=\"Modelo Inicial: \")\n",
    "\n",
    "# entrena el modelo\n",
    "rl.fit(x,y,lr=0.0001,epochs=200)\n",
    "\n",
    "#visualiza el modelo entrenado\n",
    "rnutil.plot_regresion_lineal_univariada(rl.w,rl.b,x,y,title=\"Modelo Final: \")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Regresion Lineal - Clase.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
