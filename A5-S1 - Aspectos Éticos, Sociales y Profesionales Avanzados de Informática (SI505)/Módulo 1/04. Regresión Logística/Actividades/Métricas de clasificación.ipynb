{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_fJKMUIZLIJ"
   },
   "source": [
    "# Métricas de clasificación\n",
    "\n",
    "En este cuaderno deberás implementar varias métricas de clasificación y algunas utilidades para lidiar con la salidas de los modelos.\n",
    "\n",
    "La mayoría de las soluciones puede implementarse en una o dos líneas, si utilizás las funciones de numpy. No obstante, es más importante que las implementaciones sean fáciles de leer y correctas a que sean eficientes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaGzMa1JZLIL"
   },
   "source": [
    "## 1 - Conversión entre codificaciones de la salida\n",
    "\n",
    "Implementá las funciones `onehot2label` y `label2onehot` que convierten una matriz de valores  de salida codificados como un matriz de vectores *onehot* a un vector de etiquetas y viceversa.\n",
    "\n",
    "Recordá que un vector *onehot*  tiene el valor `0` en todos sus elementos, excepto por el elemento cuyo índice es el de la clase, que tiene valor `1`.\n",
    "\n",
    "Por ejemplo `[0,0,0,0,1,0,0]` es un vector que indica la clase `4`. Además, como tiene longitud 7, sabemos que hay 7 clases, codificadas de 0 a 6. Por otro lado, observemos la siguiente matriz de salida:\n",
    "\n",
    "`[[0,0,0,0,0,1],\n",
    "  [0,0,1,0,0,0]\n",
    "]`\n",
    "Esta matriz es de `2x6`, por ende codifica la salida de 2 ejemplos, en un problema de 6 clases. La etiqueta del primer ejemplo sería la `5`, y la del segundo ejemplo la `2`.\n",
    "\n",
    "Una etiqueta codifica la clase de un ejemplo simplemente con un número. Entonces, si convertimos la matriz anterior a un vector de etiquetas, obtenemos simplemente `[5,2]`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W03gPBcZZLIO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def onehot2labels(onehot_matrix):\n",
    "    n,c=onehot_matrix.shape\n",
    "    labels = np.zeros(n,dtype=int)\n",
    "    \n",
    "    ## TODO calcular las etiquetas\n",
    "    \n",
    "    ## FIN TODO\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def labels2onehot(labels):\n",
    "    n,=labels.shape\n",
    "    classes=int(labels.max()+1)\n",
    "    onehot_matrix=np.zeros((n,classes),dtype=int)\n",
    "    \n",
    "    ## TODO calcular los vectores onehot\n",
    "    \n",
    "    ## FIN TODO\n",
    "    \n",
    "    return onehot_matrix\n",
    "\n",
    "\n",
    "\n",
    "def equal_array(a,b):\n",
    "    equals=np.all(a==b)\n",
    "    if equals:\n",
    "        print(\"Los arreglos son iguales.\")\n",
    "    else:\n",
    "        print(\"Los arreglos no son iguales.\")\n",
    "        print(\"Debió obtener:\")\n",
    "        print(a)\n",
    "        print(\"Obtuvo:\")\n",
    "        print(b)\n",
    "\n",
    "\n",
    "onehot_test=np.array([[0,0,0,0,0,1],\n",
    "  [0,0,1,0,0,0]\n",
    "])\n",
    "labels_test=np.array([5,2])\n",
    "\n",
    "print(\"Probando conversiones, todos los arreglos deben ser iguales:\")\n",
    "equal_array(labels_test,onehot2labels(onehot_test))\n",
    "equal_array(onehot_test,labels2onehot(labels_test))\n",
    "# onehot2labels y labels2onehot deben ser funciones inversas entre si.\n",
    "equal_array(labels_test,onehot2labels(labels2onehot(labels_test)))\n",
    "equal_array(onehot_test,labels2onehot(onehot2labels(onehot_test)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1fcbgjYZLIa"
   },
   "source": [
    "## 2 - Conversión de probabilidades a etiquetas.\n",
    "La salida de un modelo de clasificación con función softmax es un vector de probabilidades para cada ejemplo. Es decir, es una matriz de dimensiones `ejemplos x clases` donde nos indican la probabilidad del modelo para cada clase y ejemplo. Muchas veces queremos convertir esas probabilidades en etiquetas, seleccionando para cada ejemplo la etiqueta de la clase con mayor probabilidad.\n",
    "\n",
    "Por ejemplo, si la salida que predice un modelo es:\n",
    "\n",
    "`\n",
    "y_prob =[[0.5 , 0.2 , 0.3 ],\n",
    "         [0.1 , 0.3 , 0.6 ],\n",
    "         [0.05, 0.15, 0.8 ]\n",
    "        ]\n",
    "`\n",
    "\n",
    "Entonces las etiquetas que predice son `y_pred = [0,2,2]`, ya que:\n",
    "* En la primer fila el valor más alto es el `0.5` (columna 0)\n",
    "* En la segunda es el valor `0.6` (columna 2)\n",
    "* En la tercer fila es el valor `0.8` (columna 2)\n",
    "\n",
    "Implementá la funcion `prob2labels` que convierte una matriz de probabilidades en un vector de etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YiO4dY-2ZLIc"
   },
   "outputs": [],
   "source": [
    "def prob2labels(y_prob):\n",
    "    n,c=y_prob.shape\n",
    "    labels=np.zeros(n,dtype=int)\n",
    "    ## TODO implementar\n",
    "    \n",
    "    ## FIN TODO\n",
    "    return labels\n",
    "\n",
    "\n",
    "y_prob = np.array(\n",
    "        [[0.5 , 0.2 , 0.3 ],\n",
    "         [0.1 , 0.3 , 0.6 ],\n",
    "         [0.05, 0.15, 0.8 ]\n",
    "        ])\n",
    "\n",
    "y_pred=np.array([0,2,2])\n",
    "\n",
    "equal_array(y_pred,prob2labels(y_prob))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Me__wlf_ZLIk"
   },
   "source": [
    "## 3 - Cálculo del accuracy de un modelo\n",
    "Dado un vector de etiquetas verdaderas de salida `y`, y un vector de etiquetas que predice un modelo `y_pred`, calcula el accuracy del mismo. Recordá que el accuracy es la cantidad de veces que el modelo acierta, o sea, la cantidad de veces que `y[i]=y_pred[i]`\n",
    "\n",
    "Nota: el accuracy generalmente se codifica como un valor flotante entre 0.0 y 1.0, donde 1.0 es el mejor accuracy (100% de ejemplos bien clasificados), 0.0 el peor (0% de ejemplos bien clasificados), y, por ejemplo, 0.5 indica la mitad de ejemplos bien clasificados (50%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPxQGjSPZLIm"
   },
   "outputs": [],
   "source": [
    "def accuracy(y,y_pred):\n",
    "    accuracy=0.0\n",
    "    ## TODO implementar\n",
    "    \n",
    "    ## fin todo\n",
    "    return accuracy\n",
    "\n",
    "def equals_flotantes(etiqueta,verdadero,calculado,epsilon=0.01):\n",
    "    '''\n",
    "    Verifica que dos flotantes sean aproximadamente iguales\n",
    "    '''\n",
    "    equals= abs(verdadero-calculado)<epsilon\n",
    "    \n",
    "    if equals:\n",
    "        print(f\"{etiqueta} correcto ({calculado}).\")\n",
    "    else:\n",
    "        print(f\"{etiqueta} INCORRECTO:\")\n",
    "        print(f\"    Calculado : {calculado}\")\n",
    "        print(f\"    Verdadero : {verdadero}\")\n",
    "\n",
    "\n",
    "y =      np.array([0,1,2,2,2,2,1,0,0,2,2,0,1,0,2])\n",
    "y_pred = np.array([0,1,2,1,1,1,1,2,0,1,2,1,0,2,1])\n",
    "\n",
    "\n",
    "accuracy_calculada=accuracy(y,y_pred)\n",
    "accuracy_verdadera=0.4\n",
    "equals_flotantes(\"Accuracy\",accuracy_verdadera,accuracy_calculada)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnwtbVfnZLIs"
   },
   "source": [
    "## 4 - Matriz de confusión \n",
    "\n",
    "La matriz de confusión nos permite conocer con más detalle qué tipo de errores comete nuestro modelo. Para un problema con 5 clases, por ejemplo, la matriz tiene tamaño `5x5`; en general, para `c` clases, tiene tamaño `c x c` (sin importar el número de ejemplos).\n",
    "\n",
    "El elemento `[i,j]` de esta matriz nos dice la cantidad de veces que el modelo debió predecir la clase `i`, pero predijo la clase `j`.  Es importante notar que esta matriz entonces NO es simétrica respecto de la diagonal, ya que es posible que confunda la clase `1` con la `2`, pero no viceversa. Entonces, tener en cuenta la siguiente correspondencia es crucial para realizar correctamente este ejercicio:\n",
    "\n",
    "* `i` (fila) => clase verdadera\n",
    "* `j` (columna) => clase predicha  \n",
    "\n",
    "Implemente una función que reciba `y` y `y_pred` como en el ejercicio anterior, pero que calcule la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z748SxpUZLIu"
   },
   "outputs": [],
   "source": [
    "def confusion(y,y_pred):\n",
    "    classes=int(y.max()+1)\n",
    "    \n",
    "    matrix=np.zeros( (classes,classes))\n",
    "    \n",
    "    n,=y.shape\n",
    "    \n",
    "    ## TODO implementar\n",
    "    \n",
    "    ## FIN TODO\n",
    "    return matrix\n",
    "\n",
    "confusion_calculada=confusion(y,y_pred)\n",
    "confusion_verdadera=np.array(\n",
    "[[2, 1, 2],\n",
    " [1, 2, 0],\n",
    " [0, 5, 2]])\n",
    "\n",
    "equal_array(confusion_verdadera,confusion_calculada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iklB6orPZLI0"
   },
   "source": [
    "## 5 - Accuracy a partir de la matriz de confusión\n",
    "\n",
    "De la matriz de confusión pueden leerse muchos datos. Uno de ellos es el accuracy. En el siguiente ejercicio, te proponemos calcular el accuracy pero ahora a partir de la matriz de confusión. Considerá que en dicha matriz la diagonal principal tiene los ejemplos clasificados correctamente de cada clase, y el resto de los elementos no-diagonales los errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHr6lsoDZLI1"
   },
   "outputs": [],
   "source": [
    "def confusion2accuracy(confusion):\n",
    "    \n",
    "    c,c = confusion.shape\n",
    "    accuracy = 0.0\n",
    "    ## TODO implementar\n",
    "    # Pista: investigar la función np.diag()\n",
    "    \n",
    "    ## TODO fin \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "matriz_confusion = confusion(y,y_pred)    \n",
    "accuracy_confusion= confusion2accuracy(matriz_confusion)\n",
    "\n",
    "\n",
    "\n",
    "equals_flotantes(\"Accuracy\",accuracy_verdadera,accuracy_confusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFiUVvjcZLI9"
   },
   "source": [
    "## 6 - Precision, recall y f-measure para problemas binarios\n",
    "\n",
    "En los problemas de dos clases, podemos computar el `precision` y el `recall`, otras métricas útiles para evaluar un modelo. \n",
    "\n",
    "Recordamos que para problemas de 2 clases, podemos ver la matriz de confusión como:\n",
    "\n",
    "`\n",
    "TN FP\n",
    "FN TP\n",
    "`\n",
    "\n",
    "Donde:\n",
    "* TN: True Negative \n",
    "* FP: False Positive\n",
    "* FN: False Negative\n",
    "* TP: True Positive\n",
    "\n",
    "En base a estos valores podemos calcular:\n",
    "\n",
    "* Precision = TP / (TP+FP) \n",
    "* Recall    = TP / (TP+FN)\n",
    "\n",
    "Por otro lado, el `f-measure` o `f-score` es una métrica que balancea las otras dos, y no tiene los problemas del `accuracy`. Recordamos la fórmula `F = 2 * precision * recall / (precision + recall)`\n",
    "\n",
    "Implementa la función `confusion2metrics` que calcula estos valores a partir de la matriz de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3P8nb8-SZLI9"
   },
   "outputs": [],
   "source": [
    "def confusion2metrics(confusion):\n",
    "    c,c=confusion.shape\n",
    "    assert c==2, \"El problema de clasificación debe ser binario para calcular estas métricas\"\n",
    "    \n",
    "    precision=0.0\n",
    "    recall=0.0\n",
    "    f=0.0\n",
    "    ## TODO implementar\n",
    "    \n",
    "    ## fin todo\n",
    "    \n",
    "    return precision,recall,f\n",
    "\n",
    "\n",
    "y      = np.array([0,0,1,0,1,1,0,0,0,1,0,0,1,1])\n",
    "y_pred = np.array([0,0,1,1,1,0,1,0,0,1,0,1,1,0])\n",
    "\n",
    "matriz_confusion = confusion(y,y_pred)\n",
    "\n",
    "precision,recall,f=confusion2metrics(matriz_confusion)\n",
    "\n",
    "\n",
    "equals_flotantes(\"Precision\",precision, 0.57)\n",
    "equals_flotantes(\"Recall\",recall, 0.66)\n",
    "equals_flotantes(\"F-score\",f, 0.61)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ejercicio 4 - Métricas de clasificación.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
